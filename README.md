# AI Chatbot with Memory

An interactive AI chatbot built with **Vue.js (frontend)** and **Node.js (backend)** that remembers previous conversations using **LangChain** and **Pinecone**.  
Supports multiple users, selectable personalities, and message-based memory storage.

---

## ğŸš€ Features

- ğŸ§  **Persistent Memory** â€“ Stores user messages in Pinecone so the bot remembers context across sessions.
- ğŸ‘¥ **Multiple Users** â€“ Each user gets their own isolated memory space (auto-generated UUID).
- ğŸ­ **Personalities** â€“ Switch between _helpful_, _funny_, and _formal_ response styles.
- ğŸ’¬ **Conversation History** â€“ Keeps short-term memory for local continuity (`last 6 messages`).
- ğŸ”’ **Safety Rules** â€“ Restricts AI behavior (e.g., no code output).
- ğŸ§© **Modular Code** â€“ Clean separation of backend and frontend, easy to extend.

---

## ğŸ—ï¸ Tech Stack

| Area                 | Technology                      |
| -------------------- | ------------------------------- |
| **Frontend**         | Vue.js (Vite) + Axios           |
| **Backend**          | Node.js + Express               |
| **AI Engine**        | OpenAI GPT-4 (via LangChain)    |
| **Memory**           | Pinecone Vector Database        |
| **Vector Dimension** | 1536 (`text-embedding-3-small`) |
| **UI/UX**            | Custom CSS                      |

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/<your-username>/ai-chatbot-with-memory.git
cd ai-chatbot-with-memory
```

### 2ï¸âƒ£ Install Dependencies

#### Backend

```bash
cd backend
npm install
```

#### Frontend

```bash
cd frontend
npm install
```

### 3ï¸âƒ£ Environment Variables

#### Create a .env file inside the backend folder:

```bash
OPENAI_API_KEY=your_openai_api_key_here
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_INDEX=chatbot-memories
PORT=3000
```

### 4ï¸âƒ£ Run the Servers

#### Backend

```bash
cd backend
npm run dev
```

Server runs on: http://localhost:3000

#### Frontend

```bash
cd frontend
npm run dev
```

Frontend runs on: http://localhost:5173

---

## ğŸ’¬ How It Works

1. Each user gets a **unique userId** (stored in `localStorage`).
2. When a message is sent:
   - The last 6 messages (short-term context) are sent to the backend.
   - LangChain uses OpenAI embeddings to encode the new message.
   - Pinecone searches for similar past vectors (long-term memory).
   - The most relevant past facts are injected into the GPT prompt.
   - The AI generates a response according to the chosen personality.
   - The user message (and optionally reply) are stored in Pinecone.

ğŸ§  **Short-term memory:** Maintained locally (recent 6 messages).  
ğŸ—„ï¸ **Long-term memory:** Stored in Pinecone, retrieved via semantic similarity.

---

## ğŸ”’ Restrictions & Safety

This chatbot includes a **global restriction layer** defined in `server.js`:

```js
const restrictionPrompt = `
You are a helpful assistant, but you must follow these restrictions:
- Do NOT provide or generate any code snippets or pseudocode.
- Do NOT include Markdown code blocks or language names.
- If a user asks for code, politely refuse and explain conceptually instead.
`;
```

ğŸ›¡ï¸ You can modify or expand this section to restrict other behaviors.
